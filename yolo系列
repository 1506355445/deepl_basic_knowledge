1. yolov1 
    思想：1）将一幅图像分成SxS个网格(grid cell)， 如果某个object的中心 落在这个网格中，则这个网格就负责预测这个object。
         2) 每个网格要预测B个bounding box，每个bounding box 除了要预测位置之外，还要附带预测一个confidence值。 每个网格还要预测C个类别的分数。
    grid cell:
        YOLO将目标检测问题作为回归问题。会将输入图像分成S × S S \times SS×S的网格（cell），如果一个物体的中心点落入到一个cell中，那么该cell就要负责预测该物体，一个格子只能预测一个物体，
 会生成两个预测框。
    损失函数:
        YOLO V1每个网格单元能够预测多个边界框。为了计算true positive的损失，只希望其中一个框负责该目标，为此选择与GT具有最高IOU的那个框。
    YOLO正样本选择
        当一个真实物体的中心点落在了某个cell内时，该cell就负责检测该物体。
        具体做法是将与该真实物体有最大IoU的边框设为正样本， 这个区域的类别真值为该真实物体的类别，该边框的置信度真值为1。
    YOLO负样本选择
        除了上述被赋予正样本的边框，其余边框都为负样本。负样本没有类别损失与边框位置损失，只有置信度损失，其真值为0。
    YOLO使用预测值和GT之间的误差平方的求和（MSE）来计算损失。 损失函数包括
        localization loss -> 坐标损失（预测边界框与GT之间的误差）
        classification loss -> 分类损失
        confidence loss -> 置信度损失（框里有无目标, objectness of the box)
   缺点：
        每个网格只对应两个bounding box，当物体的长宽比不常见(也就是训练数据集覆盖不到时)，效果较差。
        原始图片只划分为7x7的网格，当两个物体靠的很近时，效果比较差。
        最终每个网格只对应一个类别，容易出现漏检(物体没有被识别到)。
        对于图片中比较小的物体，效果比较差。这其实是所有目标检测算法的通病。





