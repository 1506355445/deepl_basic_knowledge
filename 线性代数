1.张量、线性相关和生成子空间
    张量：一般来说，一个数组中的元素分布在若干维坐标的规则网格中，我们称之为张量。
    Ax=b 为了分析方程有多少个解，我们可以将A的列向量看作从原点（元素都是零的向量）出发的不同方向，确定有多少种可以到达向量b。
    在这个观点下，向量x中的每个元素表示我们应该沿着这些方向走多远。
    形式上为每个向量乘以对应标量系数之后的和，这种操作称为线性组合。
    一组向量的生成子空间是原始向量线性组合后所能抵达的点的集合。
    确定Ax=b是否有解，相当于确定向量b是否在A列向量的生成子空间中。这个特殊的生成子空间被称为A的列空间或者A的值域。
    一个列向量线性相关的方阵被称为奇异的

2.范数
    范数是将向量映射到非负值的函数。直观上来说，向量x的范数衡量从原点到点x的距离。
    L²范数称为欧几里得范数。它表示从原点出发到向量x确定的点的欧几里得距离。
    当机器学习问题中零和非零元素之间的差异非常重要时，通常会使用L1范数。L1范数经常作为表示非零元素数目的替代函数。
    最大范数表示向量中具有最大幅值的元素的绝对值
    衡量矩阵大小最常见的做法是使用Frobenius范数，其类似于向量的L²范数。
    
3.特征分解
    方阵A的特征矩阵是指与A相乘后相当于对该向量进行缩放的非零向量v：Av=λv
    作用：能够是我们在目标方向上延伸空间，在特征向量v方向的空间拉伸了λ倍
    矩阵的特征分解给了我们很多关于矩阵的有用的信息。矩阵是奇异的，当且仅当含有零特征值。
    
4.奇异值分解
    最有用的一个性质（可能）：拓展矩阵求逆到非方阵上。
    
5.行列式
    行列式等于矩阵特征值的乘积。行列式的绝对值可以用来衡量矩阵参与矩阵乘法后空间扩大或者缩小了多少。如果行列式是0，那么空间至少沿着某一维完全收缩了，使其失去了所有的体积；
    如果行列式是1，那么这个转换保持空间体积不变。
