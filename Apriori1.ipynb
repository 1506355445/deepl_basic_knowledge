{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d50b7cab-c577-48d6-a734-63141acb9571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载商品数: 50, 交易数: 1000\n",
      "1-项集数量: 48\n",
      "2-项集数量: 6\n",
      "3-项集数量: 1\n",
      "总耗时: 0.55s\n",
      "\n",
      "=== 高频项集 ===\n",
      "1-项集 (前6个):\n",
      "   'Casino'(2)\n",
      "   'Truffle'(5)\n",
      "   'Marzipan'(27)\n",
      "   'Walnut'(29)\n",
      "   'Apricot'(32)\n",
      "   'Cherry'(48)\n",
      "2-项集 (前6个):\n",
      "   'Blackberry'(15), 'Apple'(36)\n",
      "   'Gongolais'(22), 'Napoleon'(9)\n",
      "   'Apple'(12), 'Blueberry'(16)\n",
      "   'Apple'(12), 'Berry'(14)\n",
      "   'Berry'(14), 'Blueberry'(16)\n",
      "   'Lemon'(1), 'Single'(49)\n",
      "3-项集 (前6个):\n",
      "   'Apple'(12), 'Berry'(14), 'Blueberry'(16)\n",
      "\n",
      "=== 强关联规则 ===\n",
      "规则#1: 'Blackberry'(15) => 'Apple'(36)\n",
      "  支持度: 0.139, 置信度: 0.751\n",
      "\n",
      "规则#2: 'Apple'(36) => 'Blackberry'(15)\n",
      "  支持度: 0.139, 置信度: 0.799\n",
      "\n",
      "规则#3: 'Gongolais'(22) => 'Napoleon'(9)\n",
      "  支持度: 0.181, 置信度: 0.842\n",
      "\n",
      "规则#4: 'Napoleon'(9) => 'Gongolais'(22)\n",
      "  支持度: 0.181, 置信度: 0.804\n",
      "\n",
      "规则#5: 'Apple'(12) => 'Blueberry'(16)\n",
      "  支持度: 0.259, 置信度: 0.863\n",
      "\n",
      "规则#6: 'Blueberry'(16) => 'Apple'(12)\n",
      "  支持度: 0.259, 置信度: 0.915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "class OptimizedApriori:\n",
    "    def __init__(self, min_sup=0.01, min_conf=0.5):\n",
    "        self.min_sup = min_sup\n",
    "        self.min_conf = min_conf\n",
    "        self.transactions = []\n",
    "        self.goods_map = {}\n",
    "        \n",
    "    def load_data(self, goods_path, trans_path):\n",
    "        \"\"\"高效加载大规模数据\"\"\"\n",
    "        # 加载商品信息\n",
    "        with open(goods_path, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                self.goods_map[row['ID']] = row['Name']\n",
    "        \n",
    "        # 流式读取交易数据\n",
    "        with open(trans_path, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)  # Skip header\n",
    "            for row in reader:\n",
    "                if not row: continue\n",
    "                items = [item.strip() for item in row[1:] if item.strip()]\n",
    "                self.transactions.append(items)\n",
    "                \n",
    "        print(f\"已加载商品数: {len(self.goods_map)}, 交易数: {len(self.transactions)}\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"优化后的Apriori算法\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 生成频繁1-项集\n",
    "        item_counts = defaultdict(int)\n",
    "        for trans in self.transactions:\n",
    "            for item in trans:\n",
    "                item_counts[item] += 1\n",
    "                \n",
    "        freq_items = {\n",
    "            1: [tuple([item]) for item, cnt in item_counts.items() \n",
    "                if cnt / len(self.transactions) >= self.min_sup]\n",
    "        }\n",
    "        print(f\"1-项集数量: {len(freq_items[1])}\")\n",
    "        \n",
    "        # 逐层生成k-项集\n",
    "        k = 2\n",
    "        while True:\n",
    "            candidates = self._generate_candidates(freq_items[k-1])\n",
    "            if not candidates:\n",
    "                break\n",
    "                \n",
    "            # 使用事务压缩技术加速计数\n",
    "            candidate_counts = defaultdict(int)\n",
    "            for trans in self.transactions:\n",
    "                trans_set = set(trans)\n",
    "                for cand in candidates:\n",
    "                    if set(cand).issubset(trans_set):\n",
    "                        candidate_counts[cand] += 1\n",
    "                        \n",
    "            # 筛选频繁项集\n",
    "            freq_k = [\n",
    "                itemset for itemset, cnt in candidate_counts.items()\n",
    "                if cnt / len(self.transactions) >= self.min_sup\n",
    "            ]\n",
    "            \n",
    "            if not freq_k:\n",
    "                break\n",
    "                \n",
    "            freq_items[k] = freq_k\n",
    "            print(f\"{k}-项集数量: {len(freq_k)}\")\n",
    "            k += 1\n",
    "            \n",
    "        # 生成关联规则\n",
    "        rules = self._generate_rules(freq_items)\n",
    "        \n",
    "        print(f\"总耗时: {time.time()-start_time:.2f}s\")\n",
    "        return freq_items, rules\n",
    "    \n",
    "    def _generate_candidates(self, prev_items):\n",
    "        \"\"\"带剪枝的候选生成\"\"\"\n",
    "        candidates = set()\n",
    "        sorted_items = sorted(prev_items)\n",
    "        \n",
    "        # 连接步（前缀匹配）\n",
    "        for i in range(len(sorted_items)):\n",
    "            for j in range(i+1, len(sorted_items)):\n",
    "                itemset1 = sorted_items[i]\n",
    "                itemset2 = sorted_items[j]\n",
    "                \n",
    "                if itemset1[:-1] == itemset2[:-1]:\n",
    "                    new_cand = itemset1 + (itemset2[-1],)\n",
    "                    candidates.add(new_cand)\n",
    "                    \n",
    "        # 剪枝步（子集检查）\n",
    "        valid_candidates = []\n",
    "        for cand in candidates:\n",
    "            subsets = itertools.combinations(cand, len(cand)-1)\n",
    "            if all(subset in prev_items for subset in subsets):\n",
    "                valid_candidates.append(cand)\n",
    "                \n",
    "        return valid_candidates\n",
    "    \n",
    "    def _generate_rules(self, freq_items):\n",
    "        \"\"\"高效规则生成\"\"\"\n",
    "        rules = []\n",
    "        for k in range(2, len(freq_items)+1):\n",
    "            for itemset in freq_items[k]:\n",
    "                total_count = sum(1 for t in self.transactions \n",
    "                                if set(itemset).issubset(t))\n",
    "                \n",
    "                for i in range(1, k):\n",
    "                    for antecedent in itertools.combinations(itemset, i):\n",
    "                        antecedent = tuple(sorted(antecedent))\n",
    "                        consequent = tuple(sorted(set(itemset)-set(antecedent)))\n",
    "                        \n",
    "                        ante_count = sum(1 for t in self.transactions \n",
    "                                      if set(antecedent).issubset(t))\n",
    "                        \n",
    "                        if ante_count == 0:\n",
    "                            continue\n",
    "                            \n",
    "                        conf = total_count / ante_count\n",
    "                        if conf >= self.min_conf:\n",
    "                            rules.append((\n",
    "                                antecedent,\n",
    "                                consequent,\n",
    "                                total_count/len(self.transactions),\n",
    "                                conf\n",
    "                            ))\n",
    "        return rules\n",
    "    \n",
    "    def print_results(self, freq_items, rules, top_n=10):\n",
    "        \"\"\"可视化输出\"\"\"\n",
    "        print(\"\\n=== 高频项集 ===\")\n",
    "        for k in sorted(freq_items.keys()):\n",
    "            print(f\"{k}-项集 (前{top_n}个):\")\n",
    "            for itemset in freq_items[k][:top_n]:\n",
    "                names = [f\"{self.goods_map.get(i, i)}({i})\" for i in itemset]\n",
    "                print(\"  \", \", \".join(names))\n",
    "                \n",
    "        print(\"\\n=== 强关联规则 ===\")\n",
    "        for i, (antec, conseq, sup, conf) in enumerate(rules[:top_n], 1):\n",
    "            ante_names = [f\"{self.goods_map.get(i, i)}({i})\" for i in antec]\n",
    "            conseq_names = [f\"{self.goods_map.get(i, i)}({i})\" for i in conseq]\n",
    "            print(f\"规则#{i}: {', '.join(ante_names)} => {', '.join(conseq_names)}\")\n",
    "            print(f\"  支持度: {sup:.3f}, 置信度: {conf:.3f}\\n\")\n",
    "\n",
    "# ================== 使用示例 ==================\n",
    "if __name__ == \"__main__\":\n",
    "    apriori = OptimizedApriori(\n",
    "        min_sup=0.03,   # 1000条数据时建议2%-5%\n",
    "        min_conf=0.7\n",
    "    )\n",
    "    \n",
    "    # 加载数据（替换为实际路径）\n",
    "    apriori.load_data(\n",
    "        goods_path=\"goods.csv\",\n",
    "        trans_path=\"out1.csv\"\n",
    "    )\n",
    "    \n",
    "    # 运行算法\n",
    "    freq_items, rules = apriori.run()\n",
    "    \n",
    "    # 打印结果\n",
    "    apriori.print_results(freq_items, rules, top_n=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
